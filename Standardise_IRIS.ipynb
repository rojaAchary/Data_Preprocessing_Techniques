{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import datasets\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Load Data\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the iris data\n",
    "iris = datasets.load_iris()\n",
    "\n",
    "# Create a variable for the feature data\n",
    "X = iris.data\n",
    "\n",
    "# Create a variable for the target data\n",
    "y = iris.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Split Data For Cross Validation\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random split the data into four new datasets, training features, training outcome, test features, \n",
    "# and test outcome. Set the size of the test data to be 30% of the full dataset.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Standardize Feature Data\n",
    "</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the standard scaler\n",
    "sc = StandardScaler()\n",
    "\n",
    "# Compute the mean and standard deviation based on the training data\n",
    "sc.fit(X_train)\n",
    "\n",
    "# Scale the training data to be of mean 0 and of unit variance\n",
    "X_train_std = sc.transform(X_train)\n",
    "\n",
    "# Scale the test data to be of mean 0 and of unit variance\n",
    "X_test_std = sc.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[6.1, 2.8, 4.7, 1.2],\n",
       "       [5.7, 3.8, 1.7, 0.3],\n",
       "       [7.7, 2.6, 6.9, 2.3],\n",
       "       [6. , 2.9, 4.5, 1.5],\n",
       "       [6.8, 2.8, 4.8, 1.4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Feature Test Data, non-standardized\n",
    "X_test[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "135e78ef6267b613ce7b86630936d470174b66187aad9f784a45e5cc3235687c"
  },
  "kernelspec": {
   "display_name": "Python 3.6.10 64-bit ('tf-gpu': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
